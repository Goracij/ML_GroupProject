{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 331462 entries, 0 to 374605\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   name         331462 non-null  object\n",
      " 1   category     331462 non-null  object\n",
      " 2   subcategory  331462 non-null  object\n",
      " 3   country      331462 non-null  object\n",
      " 4   launched     331462 non-null  object\n",
      " 5   deadline     331462 non-null  object\n",
      " 6   goal         331462 non-null  int64 \n",
      " 7   pledged      331462 non-null  int64 \n",
      " 8   backers      331462 non-null  int64 \n",
      " 9   state        331462 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 27.8+ MB\n",
      "None\n",
      "               goal       pledged        backers          state\n",
      "count  3.314620e+05  3.314620e+05  331462.000000  331462.000000\n",
      "mean   4.152286e+04  9.939993e+03     116.456315       0.403820\n",
      "std    1.109279e+06  9.664561e+04     965.732911       0.490663\n",
      "min    0.000000e+00  0.000000e+00       0.000000       0.000000\n",
      "25%    2.000000e+03  5.000000e+01       2.000000       0.000000\n",
      "50%    5.000000e+03  7.880000e+02      15.000000       0.000000\n",
      "75%    1.500000e+04  4.609000e+03      63.000000       1.000000\n",
      "max    1.663614e+08  2.033899e+07  219382.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "# BASE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import set_config\n",
    "import pickle\n",
    "\n",
    "#VISUALIZATION\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "\n",
    "#??????????????????????? WHAT ARE YOU????????????????????????\n",
    "from scipy.stats import mode                                                        #?????????????????????????????????\n",
    "from sklearn.datasets import load_digits                                            #?????????????????????????????\n",
    "from sklearn.decomposition import PCA                                               #??????????????????????????\n",
    "from sklearn.manifold import TSNE                                                   #????????????????????????????\n",
    "from sklearn.datasets import make_classification                                    #??????????????????????????\n",
    "from scipy.special import expit                                                     #???????????????????????????\n",
    "\n",
    "\n",
    "#VOTING\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#CLASIFIERS\n",
    "from sklearn.tree import DecisionTreeClassifier                                     \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV                # search of the best params for random_forrest\n",
    "from sklearn.linear_model import SGDClassifier                                      #????????????????????????\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors                                      #????????????????????????\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC                                                         #???????????\n",
    "from sklearn.ensemble import AdaBoostClassifier                                     #?????????????\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#REGRESSORS\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#CLASTERING\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch                                               #????????????????????????????\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SCALERS and TRANSFORMATION\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline                                               # pipeline function for transformers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# metrics and processing \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore, boxcox\n",
    "from sklearn.model_selection import cross_val_score                                 #??????????????????????????\n",
    "\n",
    "\n",
    "\n",
    "# EDA data treatment\n",
    "import missingno\n",
    "\n",
    "\n",
    "# other (mainly system libs)\n",
    "import warnings\n",
    "import sys\n",
    "from io import StringIO\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import urllib.request as req\n",
    "import zipfile\n",
    "\n",
    "\n",
    "#####################################################\n",
    "# Constants\n",
    "SEED = 50\n",
    "URL1 = 'https://www.kaggle.com/api/v1/datasets/download/ulrikthygepedersen/kickstarter-projects'\n",
    "URL2 = 'https://www.kaggle.com/api/v1/datasets/download/watts2/glove6b50dtxt'\n",
    "################################################################\n",
    "\n",
    "# Downloading data\n",
    "req.urlretrieve(URL1, '/data/data.zip')\n",
    "zipfile.ZipFile('/data/data.zip', 'a').extractall(path='./data/')\n",
    "req.urlretrieve(URL2, '/data/glove.zip')\n",
    "zipfile.ZipFile('/data/glove.zip', 'a').extractall(path='./data/')\n",
    "\n",
    "# Processing downloads\n",
    "df = pd.read_csv('./data/kickstarter_projects.csv')\n",
    "\n",
    "\n",
    "df.columns = [val.strip().replace(' ','_').lower() for val in df.columns.tolist()]\n",
    "df = df.drop('id', axis=1)\n",
    "\n",
    "df = df[(df['state'] == 'Successful') | (df['state'] == 'Failed')]\n",
    "df['state'] = df['state'].map({'Successful':1 , 'Failed': 0})\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "# ## Splitting data for testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('state', axis=1), df.state, train_size=0.8, stratify=df.state, random_state=SEED)\n",
    "X_train.to_csv('./data/X_train.csv',index=False)\n",
    "X_test.to_csv('./data/X_test.csv',index=False)\n",
    "y_train.to_csv('./data/y_train.csv',index=False)\n",
    "y_test.to_csv('./data/y_test.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading splits for processing\n",
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "y_test = pd.read_csv('./data/y_test.csv')\n",
    "\n",
    "\n",
    "def calc_dol_p_back(df:pd.DataFrame)-> pd.DataFrame:\n",
    "    df['backers'] = df['backers'] + np.nextafter(0,1)\n",
    "    df['log_dol_p_back'] = df['pledged']/df['backers']\n",
    "    df['backers'] = df['backers'].astype('int') \n",
    "    return df\n",
    "\n",
    "def max_frac(ds:pd.Series)-> pd.Series:\n",
    "    if ds.max() != 0:\n",
    "        ds = ds/ds.max()\n",
    "    return ds\n",
    "\n",
    "def log10p1_of_val(val):\n",
    "    return np.log10(val+1)\n",
    "\n",
    "\n",
    "def pre_processing(df:pd.DataFrame)-> pd.DataFrame:\n",
    "# Formating dates\n",
    "    df['launched'] = pd.to_datetime(df['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['deadline'] = pd.to_datetime(df['deadline'], format='%Y-%m-%d')\n",
    "    df['lin_duration_days'] = df['deadline'] - X_train['launched']\n",
    "    df['lin_duration_days'] = max_frac(df['lin_duration_days'].dt.days.astype('int'))\n",
    "\n",
    "\n",
    "# Splitting (\"dymming\") and dumping launch dates:\n",
    "#           LAUNCH DATE\n",
    "    df['launched_day'] = df['launched'].dt.day\n",
    "    df['launched_month'] = df['launched'].dt.month\n",
    "    df['launched_year'] = df['launched'].dt.year\n",
    "    df['launched_dow'] = df['launched'].dt.day_name()\n",
    "    df = df.join(pd.get_dummies(df['launched_dow'], prefix='launched', prefix_sep='_', drop_first = False, dtype=float)).copy()\n",
    "    least_common = pd.DataFrame(df['launched_dow'].value_counts(sort=True, ascending=True)).index.tolist()[0]\n",
    "    df = df.drop('launched_'+least_common, axis=1)\n",
    "    df = df.drop(['launched_dow', 'launched'], axis=1)\n",
    "#           DEADLINE DATE\n",
    "    df['deadline_day'] = df['deadline'].dt.day\n",
    "    df['deadline_month'] = df['deadline'].dt.month\n",
    "    df['deadline_year'] = df['deadline'].dt.year\n",
    "    df['deadline_dow'] = df['deadline'].dt.day_name()\n",
    "    df = df.join(pd.get_dummies(df['deadline_dow'], prefix='deadline', prefix_sep='_', drop_first = False, dtype=float)).copy()\n",
    "    least_common = pd.DataFrame(df['deadline_dow'].value_counts(sort=True, ascending=True)).index.tolist()[0]\n",
    "    df = df.drop('deadline_'+least_common, axis=1)\n",
    "    df = df.drop(['deadline', 'deadline_dow'], axis=1)\n",
    "    \n",
    "# calculating dol_p_back:\n",
    "    df = calc_dol_p_back(df)\n",
    "  \n",
    "# Logarithmizing\n",
    "    df['goal_lin'] = max_frac(df['goal'])\n",
    "    df['pledged_lin'] = max_frac(df['pledged'])\n",
    "    df['backers_lin'] = max_frac(df['backers'])\n",
    "#    df['pledged_log10'] = df['pledged'].apply(lambda x: log10p1_of_val(x))\n",
    "#    df['backers_log10'] = df['backers'].apply(lambda x: log10p1_of_val(x))\n",
    "\n",
    "    df = df.drop(['goal', 'pledged', 'backers'], axis=1).copy()\n",
    "\n",
    "\n",
    "# Splitting (\"dymming\") and object columns:\n",
    "    obs = []\n",
    "    for val in df.drop('name', axis=1).columns.tolist():\n",
    "        if df[val].dtype.name == 'object':\n",
    "            obs.append(val)\n",
    "    for val in obs:\n",
    "        least_common = pd.DataFrame(df[val].value_counts(sort=True, ascending=True)).index.tolist()[0]\n",
    "        df = df.join(pd.get_dummies(df[val], prefix=val, prefix_sep='_', drop_first = False, dtype=int))\n",
    "        df = df.drop(val+'_'+least_common, axis=1)\n",
    "    df = df.drop(obs, axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "X_train = pre_processing(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name  -  object\n",
      "launched_day\n",
      "launched_month\n",
      "launched_year\n",
      "deadline_day\n",
      "deadline_month\n",
      "deadline_year\n",
      "log_dol_p_back\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    265169.000000\n",
       "mean         15.280172\n",
       "std           8.819738\n",
       "min           1.000000\n",
       "25%           8.000000\n",
       "50%          15.000000\n",
       "75%          23.000000\n",
       "max          31.000000\n",
       "Name: launched_day, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for val in X_train.columns.tolist():\n",
    "    try:\n",
    "        if X_train[val].max() > 1:\n",
    "            print(val)\n",
    "    except: \n",
    "        print(val, ' - ', X_train[val].dtype)\n",
    "\n",
    "X_train['launched_day'].describe()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
