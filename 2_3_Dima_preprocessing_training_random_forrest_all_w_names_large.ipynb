{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "# Output of this script - \n",
    "#\n",
    "#\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BASE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import set_config\n",
    "import pickle\n",
    "\n",
    "#VISUALIZATION\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "\n",
    "#??????????????????????? WHAT ARE YOU????????????????????????\n",
    "from scipy.stats import mode                                                        #?????????????????????????????????\n",
    "from sklearn.datasets import load_digits                                            #?????????????????????????????\n",
    "from sklearn.decomposition import PCA                                               #??????????????????????????\n",
    "from sklearn.manifold import TSNE                                                   #????????????????????????????\n",
    "from sklearn.datasets import make_classification                                    #??????????????????????????\n",
    "from scipy.special import expit                                                     #???????????????????????????\n",
    "\n",
    "\n",
    "#VOTING\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#CLASIFIERS\n",
    "from sklearn.tree import DecisionTreeClassifier                                     \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV                # search of the best params for random_forrest\n",
    "from sklearn.linear_model import SGDClassifier                                      #????????????????????????\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors                                      #????????????????????????\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC                                                         #???????????\n",
    "from sklearn.ensemble import AdaBoostClassifier                                     #?????????????\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#REGRESSORS\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#CLASTERING\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch                                               #????????????????????????????\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SCALERS and TRANSFORMATION\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# metrics and processing \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore, boxcox\n",
    "from sklearn.model_selection import cross_val_score                                 #??????????????????????????\n",
    "\n",
    "\n",
    "\n",
    "# EDA data treatment\n",
    "import missingno\n",
    "\n",
    "\n",
    "# other (mainly system libs)\n",
    "import warnings\n",
    "import sys\n",
    "from io import StringIO\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import urllib.request as req\n",
    "import zipfile\n",
    "import csv\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Constants\n",
    "\n",
    "SEED = 50\n",
    "FILE = './data/glove.840B.300d.txt'\n",
    "#FILE = './data/glove.6B.50d.txt'\n",
    "\n",
    "\n",
    "STOP_WORDS_FULL = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', \n",
    "'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', \n",
    "'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
    " 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
    "'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
    "'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', \n",
    "'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \n",
    "'s', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
    " 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \n",
    "'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", \n",
    "'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "STOP_WORDS_SHORT = ['a', 'an', 'the', 'as', 'while', 'of', 'by', 'for', 'to', \n",
    "'then', 'so', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
    " 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \n",
    "'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", \n",
    "'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "ZERO_VECTOR = [0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0\n",
    "            ]\n",
    "################################################################\n",
    "\n",
    "# Loading splits for processing\n",
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "y_test = pd.read_csv('./data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:343: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#class MyDataTransformer(TransformerMixin):\n",
    "#    def __init__(self):\n",
    "#        pass\n",
    "#    def fit(self, X, y=None):\n",
    "#        self.biggest_value = X.c1.max()\n",
    "#        return self\n",
    "#    def transform(self, X):\n",
    "#        return X.loc[X.c1 <= self.biggest_value]\n",
    "#X=load_some_pandas_dataframe()\n",
    "#pipeline.fit(X)\n",
    "#joblib.dump(pipeline, 'pipeline.pkl')\n",
    "\n",
    "\n",
    "\n",
    "def load_glove_library(file): #Borrowed with little modifications from https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "    print('Loading GloVe library '+ file)\n",
    "    glove_model = {}\n",
    "    with open(file,'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            word = line.split(' ')[0]\n",
    "            glove_model[str(word)] = np.array(line.split()[1:], dtype=np.float64)\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "def load_glove_large(file):\n",
    "    df = pd.read_csv(file, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    glove_model = {key: val.values for key, val in df.T.items()}\n",
    "    return glove_model\n",
    "\n",
    "def log_transform(df:pd.DataFrame , colname)-> pd.DataFrame:\n",
    "    return pd.DataFrame(np.log1p(df[colname]), columns=[colname])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def text_prep(text):\n",
    "    text=text.lower()\n",
    "    for val in list(string.whitespace)[1:]:\n",
    "        while val in text:\n",
    "            text = text.replace(val, ' ')\n",
    "    for char in \",.-=+_!?:;@#/|\\$%^&*()[]{}\":\n",
    "        while (char in text):\n",
    "            text = text.replace(char, ' ')\n",
    "    while '\"' in text:\n",
    "        text = text.replace('\"', ' ')\n",
    "    while \"'\" in text:\n",
    "        text = text.replace(\"'\", ' ')\n",
    "    while \" \"*6 in text:\n",
    "        text = text.replace(\" \"*6, ' ')\n",
    "    while \" \"*5 in text:\n",
    "        text = text.replace(\" \"*5, ' ')\n",
    "    while \" \"*4 in text:\n",
    "        text = text.replace(\" \"*4, ' ')\n",
    "    while \" \"*3 in text:\n",
    "        text = text.replace(\" \"*3, ' ')\n",
    "    while \" \"*2 in text:\n",
    "        text = text.replace(\" \"*2, ' ')\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def whole_name_vectorizer(text, model):\n",
    "    sent_vec = ZERO_VECTOR\n",
    "    numw = 0\n",
    "    for wrd in text.split():\n",
    "        try:\n",
    "            if numw == 0:\n",
    "                try :sent_vec = model[wrd]\n",
    "                except: sent_vec = ZERO_VECTOR\n",
    "            else:\n",
    "                try: sent_vec = np.add(sent_vec, model[wrd])\n",
    "                except: sent_vec = np.add(sent_vec, ZERO_VECTOR)\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return np.asarray(sent_vec) / numw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#For column transformer:\n",
    "def names_vectorizer(df:pd.DataFrame, colname, model)-> pd.DataFrame:\n",
    "    df['vec'+colname] = df[colname].astype('string').str.lower()\n",
    "    df['vec'+colname] = df['vec'+colname].apply(lambda x: text_prep(x))\n",
    "    for itr in range(df['vec'+colname].shape[0]):\n",
    "        df['vec'+colname].iloc[itr] = whole_name_vectorizer(df['vec'+colname].iloc[itr], model)\n",
    "    return pd.DataFrame(df['vec'+colname], columns=['vec'+colname])\n",
    "\n",
    "#For pipline:\n",
    "#def names_vectorizer_pipeline(sentence):\n",
    "#    sent_vec = ZERO_VECTOR\n",
    "#    numw = 0\n",
    "#    for wrd in sentence.split():\n",
    "#        try:\n",
    "#            if numw == 0:\n",
    "#                try :sent_vec = GLOVE_LIB[wrd]\n",
    "#                except: sent_vec = ZERO_VECTOR\n",
    "#            else:\n",
    "#                try: sent_vec = np.add(sent_vec, GLOVE_LIB[wrd])\n",
    "#                except: sent_vec = np.add(sent_vec, ZERO_VECTOR)\n",
    "#            numw+=1\n",
    "#        except:\n",
    "#            pass\n",
    "#    return np.asarray(sent_vec) / numw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_dol_p_back(df:pd.DataFrame)-> pd.DataFrame:\n",
    "    df['backers_adj'] = df['backers'] + (0.01)\n",
    "    df['dol_p_back'] = df['pledged']/df['backers_adj']\n",
    "    return pd.DataFrame(df['dol_p_back'])\n",
    "\n",
    "\n",
    "\n",
    "# Formating dates\n",
    "def pre_processing_dates(df:pd.DataFrame , colname)-> pd.DataFrame:\n",
    "    df[colname] = pd.to_datetime(df[colname])\n",
    "    df[colname+'_day_frac'] = df[colname].dt.day/31\n",
    "    df[colname+'_month_frac'] = df[colname].dt.month/12\n",
    "    df[colname+'_year_frac'] = df[colname].dt.year/2024\n",
    "    df[colname+'_dow'] = df[colname].dt.day_name()\n",
    "    return pd.DataFrame(df[[colname+'_day_frac',colname+'_month_frac',colname+'_year_frac']].join(pd.get_dummies(df[colname+'_dow'], prefix='launched', prefix_sep='_', drop_first = False, dtype=float))   )\n",
    "\n",
    "def duration_years(df:pd.DataFrame)-> pd.DataFrame:\n",
    "    df['launched'] = pd.to_datetime(df['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['deadline'] = pd.to_datetime(df['deadline'], format='%Y-%m-%d')\n",
    "    df['duration_years'] = df['deadline'] - df['launched']\n",
    "    df['duration_years'] = df['duration_years'].dt.days.astype('int')\n",
    "    return pd.DataFrame(df['duration_years']/365)\n",
    "\n",
    "def duration_days(df:pd.DataFrame)-> pd.DataFrame:\n",
    "    df['launched'] = pd.to_datetime(df['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['deadline'] = pd.to_datetime(df['deadline'], format='%Y-%m-%d')\n",
    "    df['duration_years'] = df['deadline'] - df['launched']\n",
    "    df['duration_years'] = df['duration_years'].dt.days.astype('int')\n",
    "    return pd.DataFrame(df['duration_years'])\n",
    "\n",
    "def goal_lin_norm(df:pd.DataFrame , colname)-> pd.DataFrame:\n",
    "    return pd.DataFrame(df[colname]/df[colname].max())\n",
    "\n",
    "# Just in case...\n",
    "def keep_initial(df:pd.DataFrame , columns)-> pd.DataFrame:\n",
    "    return pd.DataFrame(df[columns])\n",
    "\n",
    "def kmeans(df:pd.DataFrame , columns)-> pd.DataFrame:\n",
    "    pass\n",
    "    return\n",
    "\n",
    "\n",
    "COLUMNS_TO_KEEP = []\n",
    "GLOVE_LIB = load_glove_large(FILE)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "                    ('ct', OneHotEncoder(drop=None, handle_unknown='infrequent_if_exist', sparse_output=False), ['category']),\n",
    "                    ('sct', OneHotEncoder(drop=None, handle_unknown='infrequent_if_exist', sparse_output=False), ['subcategory']),\n",
    "                    ('ctry', OneHotEncoder(drop=None, handle_unknown='infrequent_if_exist', sparse_output=False), ['country']),\n",
    "                    ('l', FunctionTransformer(pre_processing_dates, kw_args={'colname':'launched'}, validate=False), ['launched']),\n",
    "                    ('d', FunctionTransformer(pre_processing_dates, kw_args={'colname':'deadline'}, validate=False), ['deadline']),\n",
    "                    ('dpb', FunctionTransformer(calc_dol_p_back, validate=False), ['backers', 'pledged']),\n",
    "                    ('cdy', FunctionTransformer(duration_years, validate=False), ['launched', 'deadline']),\n",
    "                    ('fmaxg', FunctionTransformer(goal_lin_norm, kw_args={'colname':'goal'}, validate=False), ['goal']),\n",
    "                    ('fmaxp', FunctionTransformer(goal_lin_norm, kw_args={'colname':'pledged'}, validate=False), ['pledged']),\n",
    "                    ('fmaxb', FunctionTransformer(goal_lin_norm, kw_args={'colname':'backers'}, validate=False), ['backers']),\n",
    "                    ('av_vec', FunctionTransformer(names_vectorizer, kw_args={'colname':'name', 'model':GLOVE_LIB}, validate=False), ['name']),\n",
    "                    ('original', FunctionTransformer(keep_initial, kw_args={'columns':COLUMNS_TO_KEEP}, validate=False), COLUMNS_TO_KEEP)\n",
    "                    ],remainder='drop').set_output(transform=\"pandas\")\n",
    "\n",
    "#data_pipeline = Pipeline(steps =  [\n",
    "#                            ('trsfr', preprocessor)\n",
    "#                            ('scale', StandardScaler()),\n",
    "#                            ('pca', PCA(0.99, random_state=0)),\n",
    "#                            ('bins', KMeans(n_clusters=14, init='k-means++', max_iter=1000, n_init='auto', random_state=SEED))\n",
    "#])\n",
    "\n",
    "\n",
    "X_train_transf = preprocessor.fit_transform(X_train)\n",
    "X_test_transf = preprocessor.transform(X_test)\n",
    "\n",
    "#X_train_transf = data_pipeline.fit_transform(X_train)\n",
    "#X_test_transf = data_pipeline.transform(X_test)\n",
    "\n",
    "#joblib.dump(data_pipeline, './models/pipeline_joblib.pkl')\n",
    "#pipeline = joblib.load('./models/pipeline_pkl.pkl')\n",
    "#X_test_load = pipeline.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasters = KMeans(n_clusters=14, init='k-means++', max_iter=1000, n_init='auto', random_state=SEED)\n",
    "\n",
    "X_train_transf['name_cluster'] = pd.Series(clasters.fit_predict(X_train_transf['av_vec__vecname'].values.tolist() ),  name='name_cluster')\n",
    "X_test_transf['name_cluster'] = pd.Series(clasters.predict(X_test_transf['av_vec__vecname'].values.tolist()),  name='name_cluster')\n",
    "\n",
    "X_train_transf = X_train_transf.drop('vec_name', axis=1)\n",
    "X_test_transf = X_test_transf.drop('vec_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   57.4s finished\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################\n",
    "#                                           MODEL           3\n",
    "model_3 = RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1, verbose = 1)\n",
    "model_3.fit(X_train_transf, y_train.values.ravel())\n",
    "##################################################################################################\n",
    "\n",
    "filename = 'models/Dima_random_forrest_all_w_namevec_bins_large.sav'\n",
    "pickle.dump(model_3, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93     39523\n",
      "           1       0.98      0.79      0.88     26770\n",
      "\n",
      "    accuracy                           0.91     66293\n",
      "   macro avg       0.93      0.89      0.90     66293\n",
      "weighted avg       0.92      0.91      0.91     66293\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGdCAYAAAAczXrvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjXklEQVR4nO3deXRUZb7u8acqJMWYghAySZhlNqARY2Q4DJEQuzkicdYrKEcW3IgH0k5xYSN224XDZVqEYLc0YDdRrnaDw22IEiXo6iAaTaP2aTSIHRQSBiUJBVRiUvcPj3W6djGkoJKKe38/vfZa1q5de7/bXvHJ7/e+tWPzer1eAQAAy7CHewAAAKB1Ef4AAFgM4Q8AgMUQ/gAAWAzhDwCAxRD+AABYDOEPAIDFEP4AAFgM4Q8AgMW0C/cAfmSbPDTcQwDaHO+b28M9BKCNSmrRs4cyk7xv/j1k5wqVNhP+AAC0GbZwD6Bl0fYHAMBiqPwBADCymbv0J/wBADAyd/YT/gAABDB55c+cPwAAFkPlDwCAkbkLf8IfAIAAdnOnP21/AAAshsofAAAjcxf+hD8AAAFY7Q8AAMyEyh8AACNzF/6EPwAAAUwe/rT9AQCwGCp/AACMTL7gj/AHAMDI3NlP+AMAEMDklT9z/gAAWAyVPwAARuYu/Al/AAAC0PYHAABmQuUPAICRyUtjwh8AACNzd/3N/rsNAAAwovIHAMDI5Av+CH8AAIzMnf20/QEAsBoqfwAAjGj7AwBgMebOfsIfAIAAJq/8mfMHAMBiqPwBADAyd+FP+AMAEIC2PwAAaA0FBQVKSUlRdHS0oqOjlZ6erq1bt/reHz9+vGw2m982Z86coK9D5Q8AgFGYCv+ePXtqyZIluvTSS+X1erVhwwZdf/31+vjjjzVs2DBJ0r333qsnnnjC95mOHTsGfR3CHwAAozD1xadOner3+sknn1RBQYF27drlC/+OHTsqISHhoq5D2x8AgBbk8XhUW1vrt3k8nvN+rrGxUS+99JLcbrfS09N9+zdu3KjY2FgNHz5ceXl5OnnyZNBjIvwBADCy2UK2uVwuOZ1Ov83lcp310p988ok6d+4sh8OhOXPmaPPmzRo6dKgk6fbbb9cf//hHvfPOO8rLy9Mf/vAH3XnnncHfntfr9V7wv5wQsk0eGu4hAG2O983t4R4C0EYltejZbfdeFbJznV71bkCl73A45HA4znh8fX29KisrVVNTo1deeUXPP/+8SkpKfL8A/Ku3335bkyZNUkVFhfr379/sMTHnDwBACzpX0J9JVFSUBgwYIElKTU3VBx98oBUrVui5554LODYtLU2SCH8AAC5aG/qef1NT01nXCJSXl0uSEhMTgzon4Q8AgFGYsj8vL09ZWVnq1auX6urqVFhYqB07dqioqEj79u1TYWGhrrvuOnXv3l179uzRggULNG7cOKWkpAR1HcIfAACjMFX+hw8f1l133aVDhw7J6XQqJSVFRUVFuvbaa3XgwAFt375dy5cvl9vtVnJysrKzs7Vw4cKgr0P4AwDQRqxdu/as7yUnJ6ukpCQk1yH8AQAwajtT/i2C8AcAwKANrfdrETzkBwAAi6HyBwDAwGby0p/wBwDAwOTZT9sfAACrofIHAMDAbvLSn/AHAMDA5NlP2x8AAKuh8gcAwMDkhT/hDwCAEV/1AwDAYkye/cz5AwBgNVT+AAAYmL3yJ/wBADAw+5w/bX8AACyGyh8AAAOTF/6EPwAARrT9AQCAqVD5AwBgYPLCn/AHAMDI7G1xs98fAAAwoPIHAMDA7Av+CH8AAAxMnv2EPwAARmYPf+b8AQCwGCp/AAAMmPMHAMBiTJ79tP0BALAaKn8AAAxo+wMAYDEmz37a/gAAWA2VPwAABiYv/Al/AACMzD7nT9sfAACLofIHAMDA5IU/4Q8AgJHd5OFP2x8AAAObzRayLRgFBQVKSUlRdHS0oqOjlZ6erq1bt/reP336tHJyctS9e3d17txZ2dnZqq6uDvr+CH8AANqInj17asmSJSorK9OHH36oiRMn6vrrr9dnn30mSVqwYIFef/11vfzyyyopKdHBgwc1ffr0oK9j83q93lAP/kLYJg8N9xCANsf75vZwDwFoo5Ja9Oy9F08M2bn+uejti/p8TEyMnnnmGd14443q0aOHCgsLdeONN0qS/vGPf2jIkCEqLS3V1Vdf3exzMudvQXN+fovm/vxW9Ym/RJL02T8r9MTGAm374F1JUr/EZD07+0GNGXaFHJFR2vbhe5qX/6QOHz8WzmEDIbVx42atXbtJR458q8GD++uxx+5XSsqQMx775ps7tWbNRlVWfqPvv29U796X6O67b9a0aZN9xzzyyBJt3lzk97kxY0Zp7dqnW/Q+0DJC+VU/j8cjj8fjt8/hcMjhcJzzc42NjXr55ZfldruVnp6usrIyNTQ0KCMjw3fM4MGD1atXr6DDn7a/BX19tFqPrF2m1JybdOV9N+nt8vf16uOrNLT3AHVs30Fvun4nr9eriQ/drdEL7lBUZKRefyLf9N97hXX85S9vy+UqUE7ODG3e/FsNHtxfs2Y9pGPHvjvj8U5ntObOvVObNuXrtdee1/TpU/Too0/p3Xd3+x03duxVeu+9P/m2pUsfa43bQRvncrnkdDr9NpfLddbjP/nkE3Xu3FkOh0Nz5szR5s2bNXToUFVVVSkqKkpdu3b1Oz4+Pl5VVVVBjYnK34Le2LXD7/XC9Ss09+e36uohKbokNk594i/R5f87W3Un3ZKkGU/n6bs/79LEkVer+OPSMIwYCK11617WzTf/TNnZWZKkxYtztWPH+/rTn7Zq9uzbA45PSxvp93rGjBu1ZcubKiv7VGPHXuXbHxUVqR49Ylp07Ggdoax18vLylJub67fvXFX/oEGDVF5erpqaGr3yyiuaMWOGSkpKQjcgUflbnt1u1y3js9SpfQeV/v1vckRGySuvPA31vmNON3jU5G3SmOFXhHGkQGjU1zfos88+1zXXpPr22e12XXPNFfr448/O+3mv16vS0jLt339Ao0al+L23e3e50tNvUGbmXVq0aJm++64m5ONH67CFcHM4HL7V+z9u5wr/qKgoDRgwQKmpqXK5XBoxYoRWrFihhIQE1dfX6/jx437HV1dXKyEhIaj7C7ryP3r0qH7/+9+rtLTU12ZISEjQNddco5kzZ6pHjx7BnhJhMLzPpSpd8aLaR0XpxKmTumHx/fqvyn06UvOt3KdP6alZv9Cj65bLZrNpyT25ahfRTokx/H+Ln77vvqtRY2OTunfv5re/e/du+vLLyrN+rq7uhMaNu0n19Q2y2+1atGi+Ro++0vf+2LFX6dprx6pnz0QdOHBQS5c+r3vvfUSbNq1SREREi90PzK+pqUkej0epqamKjIxUcXGxsrOzJUl79+5VZWWl0tPTgzpnUOH/wQcfKDMzUx07dlRGRoYGDhwo6YffOlauXKklS5aoqKhIV1555TnPc6bFD2pqkuw0IlrL3q+/0si50+Xs1Fk3js3Uhgd/o397YIb+q3Kfbvr1AhXM+6Xun3anmrxNevGdv6jsi8/U1NQU7mEDYdOpU0dt2fK8Tp48pdLSj7RkyWolJyf5pgR+9rP/WR0+aFA/DRrUTxkZd/x3NyD1LGdFWxWuNU55eXnKyspSr169VFdXp8LCQu3YsUNFRUVyOp2aNWuWcnNzFRMTo+joaM2bN0/p6elBLfaTggz/efPm6aabbtKaNWsC/sV4vV7NmTNH8+bNU2npueeFXS6XFi9e7L+zX6zUn8qytTR836B9B3+ocj764u8aNXC4/vOG/6U5Kx7XW2V/1YCZU9Q9uqu+b2xUjbtOh17aqS+rtp7nrEDb162bUxER9oDFfceOfafY2LPP19vtdvXu/cM3ZIYMGaB9+/6p3/52Y8B6gB8lJyepWzen/vnPbwj/n6BwrW8+fPiw7rrrLh06dEhOp1MpKSkqKirStddeK0latmyZ7Ha7srOz5fF4lJmZqdWrVwd9naDC/29/+5vWr19/xt+IbDabFixYoMsvv/y85znT4gfn9KvOcjRag91ukyMy0m/fsdrjkqQJI9MU1zVGr5Ve3HdVgbYgKipSw4YNVGnpR8rIGCPph7ZqaelHuvPOG5p9nqamJtXXN5z1/aqqIzp+vFY9enS/6DHDOtauXXvO99u3b6/8/Hzl5+df1HWCCv+EhATt3r1bgwcPPuP7u3fvVnx8/HnPc8bvN9LybzW/uWeBtn6wU5WHD6lLh066feLPNT7lKmU+eq8kaebkG/57/v87pQ8dqRVz87Tszy/o86+/Cu/AgRC5++6b9PDDSzR8+EClpAzRhg2v6NSp05o+fYok6aGHfqP4+B76xS9++Jl47rmNGj58kHr1SlJ9fYNKSt7Xa6+9pccfXyBJcrtPadWqDcrMHKfY2BgdOPCNnnnmOfXufYnGjh0VtvvEhbOZ/OH+QYX/Aw88oNmzZ6usrEyTJk3yBX11dbWKi4v1u9/9Ts8++2yLDBShE9c1Ri88uESJMT1Uc7JOe778XJmP3qvtH/0wXTOoZx+57lmgmC5OfVX9jZ588Tkt+9OGMI8aCJ3rrpuob7+t0cqV63XkyLcaMqS/nn/+KV/b/9Chw7L/S0Fy8uRpLV68XFVVR9S+vUP9+vXSM888quuu+2GePyLCrs8/36ctW4pUV3dCcXHdNXr0lfrP/7xHUVFRYblHXByzP9ck6Mf7btq0ScuWLVNZWZkaGxslSREREUpNTVVubq5uvvnmCxsIj/cFAvB4X+BsWvbxvoOeygzZufY+XHT+g1pZ0F/1u+WWW3TLLbeooaFBR48elSTFxsYq0jBfDAAA2qYLfsJfZGSkEhMTQzkWAADaBJN3/Xm8LwAARmaf82eJPQAAFkPlDwCAAV/1AwDAYmj7AwAAU6HyBwDAwOyVP+EPAICB2cOftj8AABZD5Q8AgIHN5KUx4Q8AgIHZ2/6EPwAABmYPf5M3NgAAgBGVPwAARiav/Al/AAAMaPsDAABTofIHAMCAr/oBAGAxtP0BAICpUPkDAGBg9sqf8AcAwMDs4U/bHwAAi6HyBwDAwGY3d+VP+AMAYGD2tj/hDwCAgcmznzl/AACshsofAAAD2v4AAFiM2cOftj8AABZD5Q8AgAFf9QMAwGJo+wMAAFMh/AEAMLDZQrcFw+VyadSoUerSpYvi4uI0bdo07d271++Y8ePHy2az+W1z5swJ6jqEPwAABsZwvZgtGCUlJcrJydGuXbv01ltvqaGhQZMnT5bb7fY77t5779WhQ4d829NPPx3UdZjzBwCgjdi2bZvf6/Xr1ysuLk5lZWUaN26cb3/Hjh2VkJBwwdeh8gcAwMBmt4Vsuxg1NTWSpJiYGL/9GzduVGxsrIYPH668vDydPHkyqPNS+QMAYBDK1f4ej0cej8dvn8PhkMPhOOfnmpqaNH/+fI0ePVrDhw/37b/99tvVu3dvJSUlac+ePXr44Ye1d+9e/fnPf272mAh/AACMQhj+LpdLixcv9tu3aNEiPf744+f8XE5Ojj799FO99957fvtnz57t++fLLrtMiYmJmjRpkvbt26f+/fs3a0yEPwAALSgvL0+5ubl++85X9d9333164403tHPnTvXs2fOcx6alpUmSKioqCH8AAC5UKJ/x05wW/4+8Xq/mzZunzZs3a8eOHerbt+95P1NeXi5JSkxMbPaYCH8AAAzsYXrCX05OjgoLC/Xqq6+qS5cuqqqqkiQ5nU516NBB+/btU2Fhoa677jp1795de/bs0YIFCzRu3DilpKQ0+zqEPwAAbURBQYGkHx7k86/WrVunmTNnKioqStu3b9fy5cvldruVnJys7OxsLVy4MKjrEP4AABiE69n+Xq/3nO8nJyerpKTkoq9D+AMAYBCutn9r4SE/AABYDJU/AAAGZq/8CX8AAAwIfwAALCZcC/5aC3P+AABYDJU/AAAGdpm78if8AQAwuMi/xNvm0fYHAMBiqPwBADAw+4I/wh8AAAOzf9WPtj8AABZD5Q8AgIHZK3/CHwAAA7OHP21/AAAshsofAAADGw/5AQDAWsze9if8AQAwMHv4M+cPAIDFUPkDAGBg9sqf8AcAwMDk2U/bHwAAq6HyBwDAgLY/AAAWY/bwp+0PAIDFUPkDAGDAE/4AALAY2v4AAMBUqPwBADAwe+VP+AMAYED4AwBgMTaThz9z/gAAWAyVPwAABnZzF/6EPwAARnaTf8+ftj8AABZD5Q8AgAGr/QEAsBhW+wMAgFbhcrk0atQodenSRXFxcZo2bZr27t3rd8zp06eVk5Oj7t27q3PnzsrOzlZ1dXVQ1yH8AQAwsNtsIduCUVJSopycHO3atUtvvfWWGhoaNHnyZLndbt8xCxYs0Ouvv66XX35ZJSUlOnjwoKZPnx7UdWj7AwBgEK45/23btvm9Xr9+veLi4lRWVqZx48appqZGa9euVWFhoSZOnChJWrdunYYMGaJdu3bp6quvbtZ1qPwBAGhBHo9HtbW1fpvH42nWZ2tqaiRJMTExkqSysjI1NDQoIyPDd8zgwYPVq1cvlZaWNntMhD8AAAY2my1km8vlktPp9NtcLtd5x9DU1KT58+dr9OjRGj58uCSpqqpKUVFR6tq1q9+x8fHxqqqqavb90fYHAMAglG3/vLw85ebm+u1zOBzn/VxOTo4+/fRTvffeeyEby4/aTPi7/7Is3EMA2py57zwb7iEAbVLBhKUtev5QtsUdDkezwv5f3XfffXrjjTe0c+dO9ezZ07c/ISFB9fX1On78uF/1X11drYSEhGafn7Y/AABthNfr1X333afNmzfr7bffVt++ff3eT01NVWRkpIqLi3379u7dq8rKSqWnpzf7Om2m8gcAoK0I10N+cnJyVFhYqFdffVVdunTxzeM7nU516NBBTqdTs2bNUm5urmJiYhQdHa158+YpPT292Sv9JcIfAIAA4fqqX0FBgSRp/PjxfvvXrVunmTNnSpKWLVsmu92u7OxseTweZWZmavXq1UFdh/AHAKCN8Hq95z2mffv2ys/PV35+/gVfh/AHAMDAbu5H+xP+AAAY2WTu9Ge1PwAAFkPlDwCAQbgW/LUWwh8AAAOzz/nT9gcAwGKo/AEAMDD7gj/CHwAAA+b8AQCwGOb8AQCAqVD5AwBgEK4/7NNaCH8AAAzsJl/wR9sfAACLofIHAMDA7Av+CH8AAAzMPudP2x8AAIuh8gcAwMDsC/4IfwAADMw+50/bHwAAi6HyBwDAwOwL/gh/AAAM+MM+AABYjNnnxM1+fwAAwIDKHwAAA+b8AQCwGLPP+dP2BwDAYqj8AQAwMPtDfgh/AAAMbCZ/vC9tfwAALIbKHwAAA9r+AABYDKv9AQCAqVD5AwBgYPYFf4Q/AAAGzPkDAGAxzPkDAABTofIHAMDA7H/Yh8ofAAADewi3YOzcuVNTp05VUlKSbDabtmzZ4vf+zJkzZbPZ/LYpU6Zc0P0BAIA2wO12a8SIEcrPzz/rMVOmTNGhQ4d824svvhj0dWj7AwBgEK4Ff1lZWcrKyjrnMQ6HQwkJCRd1HSp/AAAMjK31i9k8Ho9qa2v9No/Hc8Fj27Fjh+Li4jRo0CDNnTtXx44dC/ochD8AAC3I5XLJ6XT6bS6X64LONWXKFL3wwgsqLi7WU089pZKSEmVlZamxsTGo89D2BwDAIJSVcV5ennJzc/32ORyOCzrXrbfe6vvnyy67TCkpKerfv7927NihSZMmNfs8hD8AAAah/Kqfw+G44LA/n379+ik2NlYVFRVBhT9tfwAAfqK+/vprHTt2TImJiUF9jsofAACDcK32P3HihCoqKnyv9+/fr/LycsXExCgmJkaLFy9Wdna2EhIStG/fPj300EMaMGCAMjMzg7oO4Q8AgEG4nu/34YcfasKECb7XP64VmDFjhgoKCrRnzx5t2LBBx48fV1JSkiZPnqxf/epXQU8rEP4AABiE6/G+48ePl9frPev7RUVFIbkOc/4AAFgMlT8AAAb2sDX+WwfhDwCAgcn/qB9tfwAArIbKHwAAg3B91a+1EP4AABjYTD7nT9sfAACLofIHAMDA5F1/wh8AACOzf9WPtj8AABZD5Q8AgEG4Hu/bWgh/AAAMTJ79hD8AAEbM+QMAAFOh8gcAwIA5fwAALMbsbXGz3x8AADCg8gcAwIC2PwAAFmP28KftDwCAxVD5AwBgYPbKmPAHAMCAtj8AADAVKn8AAAxsJn+8L+EPAICB3dzZT/gDAGBk9sqfOX8AACyGyh8AAAO7yVf7E/4AABiYPPtp+wMAYDVU/gAAGJh9wR/hDwCAgdnn/Gn7AwBgMVT+AAAYmLvuJ/wtZU3+X/Tc6m1++/r0jdPmNxae8fjXNr+vRQs3+u2Limqn9z9e2mJjBMLpq20VOvJxlU5WnZA9KkLOft3U/4bB6pTQ2XfMN+9Wqnr3N6o7UKvG099r7NLJiuwYGcZRoyWYve1P+FtM/wGJWvN8ju91RLtzz/x07tze75cDk/88wOKOf/6tev5bb3Xp01XeJq++3PIPla/crasXjVOE44f/XDbVNypmWA/FDOuhL7fsDfOIgQvDnL/FRETYFdsj2rd169b53B+w2fyO7x4b3ToDBcJg5P1XKfGaZHVO6qIuPaM1ZMYIeb49pdrKGt8xyZP6qs+UAXL27RbGkaKl2Wy2kG3B2Llzp6ZOnaqkpCTZbDZt2bLF732v16tf/vKXSkxMVIcOHZSRkaEvvvgi6Psj/C2msvKIrh2/UD/PXKxHH9qgQwe/Pefxp056lJWxSFMm/VLz7/ut9lUcaqWRAuH3/anvJUmRHaPCPBK0NlsIt2C43W6NGDFC+fn5Z3z/6aef1sqVK7VmzRq9//776tSpkzIzM3X69OmgrkPb30KGp/TRE0/eod594nT0SK2eK9iqe+5aoVdezVOnTu0Dju/dN06LfnW7Bg5MUt2JU/rDurc1845leuXVPMUnUPXA3LxNXn3x8t/l7N9NnS/pEu7hoJWFa84/KytLWVlZZ3zP6/Vq+fLlWrhwoa6//npJ0gsvvKD4+Hht2bJFt956a7OvE/LK/8CBA7rnnnvOeYzH41Ftba3f5vHUh3ooMBgzdqiuzbxcAwddomvGDNGqgjk6UXdKb277+IzHjxjZV1Ovv0qDhvTUlaMu1bMr/kPdunXWK//3r608cqD1ff7Sp3J/U6dh/3F5uIeCn7gzZ54n6PPs379fVVVVysjI8O1zOp1KS0tTaWlpUOcKefh/++232rBhwzmPcblccjqdftuzT20K9VBwHl2iO6pX7zgdqDzSrOMjIyM0aEjPZh8P/FTtffFTHf3ksC7PvVrtu3UI93AQBrYQ/u9MmedyuYIeU1VVlSQpPj7eb398fLzvveYKuu3/2muvnfP9L7/88rznyMvLU25urt++xoiSYIeCi3TS7dHXB47qZ/8+qlnHNzY2qeKLgxo9dmgLjwwID6/Xq89f+kxHyqt0RW66OsR2DPeQECah7PqfKfMcDkfoLnABgg7/adOmyWazyev1nvWY861udDgcATd+8nsW1LS0pc9s0bjxw5SUFKPDh2u0Jn+r7BE2TbnuCknSwrw/KC7OqfsX/Lsk6bnVW5Uyoo+Se/VQXd0pbfh9sQ4d/E43ZKeH8zaAFvP5i5+q+oODumzulYpoHyFPzQ+LqNp1iFREVIQkyVNzWvW1Hp064pYkub+pU0T7CLWP6aDITvx3DIHOlHkXIiEhQZJUXV2txMRE3/7q6mqNHDkyqHMFHf6JiYlavXq1b7GBUXl5uVJTU4M9LVpBdfVx5T24QTXH3eoW01kjr+ivFwpzFRPzw2KmqkPf+S1yqas9pScWvaRjR2sVHd1RQ4Yla/3G+eo/IPFslwB+0r7ZWSlJ+njpLr/9Q+5KUeI1yb5jvvp///PVqo/+T2nAMfjpa4t/2Kdv375KSEhQcXGxL+xra2v1/vvva+7cuUGdK+jwT01NVVlZ2VnD/3xdAYTPU8/OPOf7z6+/3+/1A49M1wOPTG/BEQFty8Q1PzvvMf2mDlS/qQNbYTQIp3CF/4kTJ1RRUeF7vX//fpWXlysmJka9evXS/Pnz9etf/1qXXnqp+vbtq8cee0xJSUmaNm1aUNcJOvwffPBBud3us74/YMAAvfPOO8GeFgAAy/vwww81YcIE3+sf1wrMmDFD69ev10MPPSS3263Zs2fr+PHjGjNmjLZt26b27QO/rn0uNm8bKdNPfl8U7iEAbc4v3uXnAjiTggkt+zdGvqx7MWTn6tfltpCdK1R4yA8AAAZtcc4/lHi8LwAAFkPlDwCAQbB/kOenhvAHAMDA3NFP+AMAEIA5fwAAYCpU/gAAGDDnDwCAxZg7+mn7AwBgOVT+AAAYmH3BH+EPAICB2ef8afsDAGAxVP4AABiYu+4n/AEACEDbHwAAmAqVPwAABqz2BwDAYgh/AAAsxuRT/sz5AwBgNVT+AAAY0PYHAMBizB7+tP0BALAYKn8AAAzMvuCP8AcAIIC505+2PwAAFkPlDwCAgdmf7U/4AwBgYO7op+0PAIDlUPkDAGBg9u/5E/4AABgw5w8AgMWYO/qZ8wcAwHKo/AEAMGDOHwAAizH7nD9tfwAALIbKHwAAA9r+AABYjMm7/rT9AQBoKx5//HHZbDa/bfDgwSG/DpU/AAAG4Wz7Dxs2TNu3b/e9btcu9FFN+AMAECB84d+uXTslJCS06DVo+wMA0II8Ho9qa2v9No/Hc9bjv/jiCyUlJalfv3664447VFlZGfIxEf4AAASwh2xzuVxyOp1+m8vlOuNV09LStH79em3btk0FBQXav3+/xo4dq7q6upDenc3r9XpDesYLdPL7onAPAWhzfvEuPxfAmRRMWNqi5/c0vh26k30/OqDSdzgccjgc5/3o8ePH1bt3by1dulSzZs0K2ZCY8wcAIEDo5vybG/Rn0rVrVw0cOFAVFRUhG49E2x8AgDbrxIkT2rdvnxITE0N6XsIfAIAAoZvzD8YDDzygkpISffXVV/rrX/+qG264QREREbrttttCclc/ou0PAIBRmB7x9/XXX+u2227TsWPH1KNHD40ZM0a7du1Sjx49Qnodwh8AgDbipZdeapXrEP4AABjwh30AALAccy+JM/fdAQCAAFT+AAAEoO0PAIDFmLsxbu67AwAAAaj8AQAwYLU/AACWQ/gDAGAx5p4VN/fdAQCAAFT+AAAEoO0PAICl2EzeGDf33QEAgABU/gAABKDtDwCAtdjMHf60/QEAsBgqfwAAApi7Nib8AQAwMPvjfc39qw0AAAhA5Q8AQABzV/6EPwAAAczdGCf8AQAIYO7K39y/2gAAgABU/gAAGJj92f6EPwAAAWj7AwAAE6HyBwAggLkrf8IfAIAA5m6Mm/vuAABAACp/AAAMbCb/k76EPwAAAcwd/rT9AQCwGCp/AAACmLs2JvwBAAhg7rY/4Q8AgIHZH+9r7rsDAAABqPwBAAhg7ra/zev1esM9CLQdHo9HLpdLeXl5cjgc4R4O0CbwcwGzIfzhp7a2Vk6nUzU1NYqOjg73cIA2gZ8LmA1z/gAAWAzhDwCAxRD+AABYDOEPPw6HQ4sWLWJRE/Av+LmA2bDgDwAAi6HyBwDAYgh/AAAshvAHAMBiCH8AACyG8IdPfn6++vTpo/bt2ystLU27d+8O95CAsNq5c6emTp2qpKQk2Ww2bdmyJdxDAkKC8IckadOmTcrNzdWiRYv00UcfacSIEcrMzNThw4fDPTQgbNxut0aMGKH8/PxwDwUIKb7qB0lSWlqaRo0apVWrVkmSmpqalJycrHnz5umRRx4J8+iA8LPZbNq8ebOmTZsW7qEAF43KH6qvr1dZWZkyMjJ8++x2uzIyMlRaWhrGkQEAWgLhDx09elSNjY2Kj4/32x8fH6+qqqowjQoA0FIIfwAALIbwh2JjYxUREaHq6mq//dXV1UpISAjTqAAALYXwh6KiopSamqri4mLfvqamJhUXFys9PT2MIwMAtIR24R4A2obc3FzNmDFDV155pa666iotX75cbrdbd999d7iHBoTNiRMnVFFR4Xu9f/9+lZeXKyYmRr169QrjyICLw1f94LNq1So988wzqqqq0siRI7Vy5UqlpaWFe1hA2OzYsUMTJkwI2D9jxgytX7++9QcEhAjhDwCAxTDnDwCAxRD+AABYDOEPAIDFEP4AAFgM4Q8AgMUQ/gAAWAzhDwCAxRD+AABYDOEPAIDFEP4AAFgM4Q8AgMUQ/gAAWMz/B9HNUxQk3k8HAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_3 = model_3.predict(X_test_transf)\n",
    "#pred_3 = (model_3.predict_proba(X_test_transf)[:,1] >= 0.4).astype(bool)\n",
    "\n",
    "conf_mat_3 = confusion_matrix(y_test, pred_3)/1000\n",
    "print(classification_report(y_test, pred_3))\n",
    "\n",
    "sns.heatmap(conf_mat_3, annot=True,  cmap='YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documentary of a DSLR Movie  (Canceled)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droped = pd.read_csv('./data/droped_states.csv')\n",
    "droped['state']\n",
    "X_drop = droped[(droped['state'] == 'Canceled') | (droped['state'] == 'Live')].drop('state', axis=1)\n",
    "y_drop = droped[(droped['state'] == 'Canceled') | (droped['state'] == 'Live')]['state'].map({'Canceled':0, 'Live':1})\n",
    "\n",
    "X_drop_pre = preprocessor.transform(X_drop)\n",
    "X_drop_pre['original__name'].iloc[489]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "489",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 489",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_drop_pre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnames_vectorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_drop_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal__name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGLOVE_LIB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_drop_pre \u001b[38;5;241m=\u001b[39m X_drop_pre\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal__name\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_drop_pre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(clasters\u001b[38;5;241m.\u001b[39mpredict(X_drop_pre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()),  name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 70\u001b[0m, in \u001b[0;36mnames_vectorizer\u001b[1;34m(df, colname, model)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m itr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(new_col\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     69\u001b[0m     vec_mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 70\u001b[0m     new_col[itr] \u001b[38;5;241m=\u001b[39m whole_name_vectorizer(\u001b[43mnew_col\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitr\u001b[49m\u001b[43m]\u001b[49m, model)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(new_col)\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 489"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_drop_pre['vec_name'] = names_vectorizer(df=X_drop_pre, colname='original__name', model=GLOVE_LIB)\n",
    "X_drop_pre = X_drop_pre.drop('original__name', axis=1)\n",
    "X_drop_pre['name_cluster'] = pd.Series(clasters.predict(X_drop_pre['vec_name'].values.tolist()),  name='name_cluster')\n",
    "X_drop_pre = X_drop_pre.drop('vec_name', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred_droped_3 = model_3.predict(X_drop_trans)\n",
    "#pred_droped_3 = (model_3.predict_proba(X_drop_trans)[:,1] >= 0.4).astype(bool)\n",
    "\n",
    "conf_mat_drop = confusion_matrix(y_drop, pred_droped_3)/1000\n",
    "\n",
    "print(classification_report(y_drop, pred_droped_3))\n",
    "\n",
    "sns.heatmap(conf_mat_drop, annot=True,  cmap='YlGn')\n",
    "\n",
    "TEST_DATA_LINE = pd.DataFrame({'name': ['LETS TRY SOMETHING UNUSUAL'],\n",
    "                'category': ['Music'],\n",
    "                'subcategory': ['MADNESS'],\n",
    "                'country': ['Germany'],\n",
    "                'launched': ['2012-06-16 23:05:26'],\n",
    "                'deadline': ['2032-06-16'],\n",
    "                'goal': [100000],\n",
    "                'pledged': [2000],\n",
    "                'backers':[15]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
